{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Notebook that generates summary information for tracks in a particular media file.\n",
    "#\n",
    "# The following outputs will be generated:\n",
    "# - Summary .csv file providing track information in the media\n",
    "# - For each track, a folder containing images of each detection, a track animated graphic\n",
    "#   and a summary .csv file providing detection information\n",
    "#\n",
    "# Review the \"Editable Section\" for parameters required to be edited by the user.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tator in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (0.0.17)\n",
      "Requirement already satisfied: certifi in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (from tator) (2020.6.20)\n",
      "Requirement already satisfied: urllib3>=1.15 in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (from tator) (1.25.9)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (from tator) (2.8.1)\n",
      "Requirement already satisfied: tator-tuspy in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (from tator) (0.2.5)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (from tator) (1.15.0)\n",
      "Requirement already satisfied: requests in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (from tator) (2.24.0)\n",
      "Requirement already satisfied: future>=0.16.0 in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (from tator-tuspy->tator) (0.18.2)\n",
      "Requirement already satisfied: aiohttp>=3.6.2 in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (from tator-tuspy->tator) (3.6.2)\n",
      "Requirement already satisfied: tinydb>=3.5.0 in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (from tator-tuspy->tator) (4.1.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (from requests->tator) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (from requests->tator) (3.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (from aiohttp>=3.6.2->tator-tuspy->tator) (19.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (from aiohttp>=3.6.2->tator-tuspy->tator) (1.5.1)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (from aiohttp>=3.6.2->tator-tuspy->tator) (3.0.1)\n",
      "Requirement already satisfied: multidict<5.0,>=4.5 in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (from aiohttp>=3.6.2->tator-tuspy->tator) (4.7.6)\n",
      "Requirement already satisfied: progressbar2 in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (3.51.4)\n",
      "Requirement already satisfied: python-utils>=2.3.0 in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (from progressbar2) (2.4.0)\n",
      "Requirement already satisfied: six in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (from progressbar2) (1.15.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mark.taipan\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Install and import relevant modules\n",
    "#\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from types import SimpleNamespace\n",
    "\n",
    "!{sys.executable} -m pip install tator\n",
    "!{sys.executable} -m pip install progressbar2\n",
    "import tator\n",
    "import progressbar\n",
    "\n",
    "!{sys.executable} -m pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************************\n",
    "# EDITABLE SECTION\n",
    "# ****************************************************************\n",
    "\n",
    "# Tator URL\n",
    "host = \"https://.tator.io\"\n",
    "\n",
    "# User-specific access token\n",
    "token = \"\"\n",
    "\n",
    "# Media with tracks to process\n",
    "media_id = \n",
    "\n",
    "# Output directory that will contain all the track data\n",
    "output_directory = './'\n",
    "\n",
    "# Set to true if images should be obtained for the localizations and states\n",
    "generate_images = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Grab project information\n",
    "#\n",
    "\n",
    "# Connect to tator\n",
    "tator_api = tator.get_api(host=host, token=token)\n",
    "\n",
    "# Get related media information\n",
    "media = tator_api.get_media(id=media_id)\n",
    "\n",
    "# Get the project ID\n",
    "project_id = media.project\n",
    "\n",
    "# Grab the localization type that is a box. It's assumed that this project\n",
    "# has been set up to only have one localization box type (that will be the detections)\n",
    "box_type_counts = 0\n",
    "detection_type_id = None\n",
    "localization_types = tator_api.get_localization_type_list(project=project_id)\n",
    "for loc_type in localization_types:\n",
    "    if loc_type.dtype == 'box':\n",
    "        detection_type_id = loc_type.id\n",
    "        box_type_counts += 1 \n",
    "        \n",
    "if box_type_counts > 1:\n",
    "    print(\"WARNING: More than one 'box' type in localization type list\")\n",
    "    \n",
    "if detection_type_id is None:\n",
    "    print(\"ERROR: Could not find a 'box' type in localization type list\")\n",
    "    \n",
    "# Grab the versions associated with this project\n",
    "# This will be used later when collecting the detection data\n",
    "versions = tator_api.get_version_list(project=project_id)\n",
    "\n",
    "version_id_name_map = {}\n",
    "for version in versions:\n",
    "    version_id_name_map[version.id] = version.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Get the tracks that are associated with the media\n",
    "#\n",
    "tracks = tator_api.get_state_list(project=project_id, media_id=[media_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create a summary file that has high level information about each track\n",
    "#\n",
    "tracks = tator_api.get_state_list(project=project_id, media_id=[media_id])\n",
    "track_data_list = []\n",
    "for track in tracks:\n",
    "\n",
    "    track_data = {}\n",
    "    track_data['project_id'] = project_id\n",
    "    track_data['media_id'] = media_id\n",
    "    track_data['media_name'] = media.name\n",
    "    track_data['track_id'] = track.id\n",
    "    track_data['start_frame'] = track.frame\n",
    "    track_data['number_of_detections'] = len(track.localizations)\n",
    "    track_data['data_folder'] = os.path.join(output_directory,'tracks',f'track_{track.id}')\n",
    "    track_data_list.append(track_data)\n",
    "    \n",
    "# Convert list of dictionaries into a pandas DataFrame and the save it as a csv in the output directory\n",
    "# This .csv file will contain an entry for each track in this media\n",
    "track_summary_df = pd.DataFrame(track_data_list)\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "final_filename = os.path.join(output_directory, f'project_{project_id}_media_{media_id}_tracks_summary.csv')\n",
    "track_summary_df.to_csv(final_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Now, go through each track and process the detection data.\n",
    "# A new folder will be created in the output directory specifically for the track.\n",
    "# All the detection information will be stored in a .csv file\n",
    "# Images of the detections and an animated state graphic will be generated if requested\n",
    "# These images will be stored in the track output folder.\n",
    "#\n",
    "for track in tracks:\n",
    "    \n",
    "    # Create the directory that we will dump the data to\n",
    "    track_output_directory = os.path.join(output_directory, f'track_{track.id}')\n",
    "    os.makedirs(track_output_directory, exist_ok=True)\n",
    "\n",
    "    # Loop through each detection in the track, grab information to be stored\n",
    "    # in the .csv summary file, and create the thumbnail\n",
    "    detection_data_list = []\n",
    "    for detection_id in track.localizations:\n",
    "            \n",
    "        # Get the current track detection\n",
    "        detection = tator_api.get_localization(id=detection_id)\n",
    "            \n",
    "        # Create the thumbnail\n",
    "        image_filename = 'N/A'\n",
    "        if generate_images:\n",
    "            image_path = tator_api.get_localization_graphic(\n",
    "                id=detection.id,\n",
    "                use_default_margins=False,\n",
    "                margin_x=0,\n",
    "                margin_y=0)\n",
    "            image_filename = f'frame_{detection.frame:05d}_track_{track.id}_det_{detection.id}.png'\n",
    "            image_folder = os.path.join(track_output_directory, 'detection_images')\n",
    "            target_path = os.path.join(image_folder, image_filename)\n",
    "            os.makedirs(image_folder, exist_ok=True)\n",
    "            shutil.move(image_path, target_path)\n",
    "\n",
    "        # Get the mathcing version name\n",
    "        version_name = ''\n",
    "        if detection.version in version_id_name_map:\n",
    "            version_name = version_id_name_map[detection.version]\n",
    "        \n",
    "        # Gather the data for the track summary file\n",
    "        det_data = {}\n",
    "        det_data['annotation_id'] = detection.id\n",
    "        det_data['media_id'] = media.id\n",
    "        det_data['media_name'] = media.name\n",
    "        det_data['media_height'] = media.height\n",
    "        det_data['media_width'] = media.width\n",
    "        det_data['frame'] = detection.frame\n",
    "        det_data['x'] = detection.x\n",
    "        det_data['y'] = detection.y\n",
    "        det_data['width'] = detection.width\n",
    "        det_data['height'] = detection.height\n",
    "        det_data['image'] = image_filename\n",
    "        det_data['version'] = version_name\n",
    "        det_data.update(detection.attributes)\n",
    "        detection_data_list.append(det_data)\n",
    "    \n",
    "    # Create the animated state graphic associated with the track using the first set of localizations\n",
    "    # Note, there is a cap of 100 frames\n",
    "    if generate_images:\n",
    "        image_path = tator_api.get_state_graphic(id=track.id, mode='animate', force_scale=\"240x240\")\n",
    "        image_filename = f'track_{track.id}_initial_timeline_animation.gif'\n",
    "        image_folder = os.path.join(track_output_directory)\n",
    "        target_path = os.path.join(image_folder, image_filename)\n",
    "        os.makedirs(image_folder, exist_ok=True)\n",
    "        shutil.move(image_path, target_path)\n",
    "    \n",
    "    # Save the detection information to a track summary csv file\n",
    "    track_summary_df = pd.DataFrame(detection_data_list)\n",
    "    final_filename = os.path.join(track_output_directory, f'project_{project_id}_media_{media_id}_track_{track.id}_summary.csv')\n",
    "    track_summary_df.to_csv(final_filename, index=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
